### Assigning Workloads to Specific Nodes

- Let us start with a simple example. Imagine a three-node cluster:
  1. Two nodes are smaller with lower hardware resources
  2. One node is larger with higher hardware resources
- You have different workloads running in your cluster, but you want to:
  - Dedicate data processing workloads that require high resources to the larger node
- In the default Kubernetes setup:
  - Any Pod can run on any node
  - For example, Pod C might get scheduled on Node 2 or Node 3, which is not ideal for resource-heavy jobs

### Solution: Limiting Pod Placement

- To solve this, we can restrict Pods to run only on specific nodes. This can be achieved in two ways:
  1. Using NodeSelectors (simple and straightforward)
  2. Using Node Affinity (more flexible, introduced later)

### Using NodeSelectors:

- To use a NodeSelector:

  1. Modify the Pod definition file:

     - Add a <code>nodeSelector</code> property under the <code>spec</code> section
     - Specify a key-value pair to match the desired node label. For example:

     ```
     apiVersion: v1
     kind: Pod
     metadata:
         name: myapp-pod
     spec:
         containers:
         - name: data-processor
           image: data-processor
         nodeSelector:
           size: large
     ```

  2. But where does <code>size: large</code> come from?
     - The key-value pair (<code>size: large</code>) represents a label that must be assigned to the target node

### Labeling Nodes

- Labels are key-value pairs assigned to objects in Kubernetes, such as:
  - Nodes
  - Pods
  - Services
  - Deployment
- To use a NodeSelector, you must first label your node. For example:
  - Label a node using the following command:
    ```
    kubectl label nodes <node-name> size=large
    ```

### How NodeSelector Works

- Once the node is labeled:

  - Add the <code>nodeSelectors</code> to the Pod definition file with the label:
    ```
    spec:
        nodeSelector:
            size: large
    ```
    - When the Pod is created, the Kubernetes scheduler ensures that the Pod is placed on the node with the matching lable (<code>size: large</code>)

- In our case:
  - Pod C will now be scheduled on Node 1, as designed

### Limitations of NodeSelectors

- While NodeSelectors are simple and effective, they have limitations:

  - NodeSelectors only support exact match on labels:
  - Complex conditions like:
    - Place the Pod on a large or medium node
    - Avoid scheduling Pods on small nodes

- To handle such scenarios, Kubernetes introduced Node Affinity and Anti-Affinity features, which we will explore in the next lecture.
